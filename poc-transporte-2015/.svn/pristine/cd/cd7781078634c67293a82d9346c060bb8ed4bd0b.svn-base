# -*- coding: utf-8 -*-
import sys
import json
import re
import networkx as nx
import os
#import pysolr
import pymongo
from getSolrQuery import getSolrQuery;

class CreateRetweetsRelationshipsGraph:
    def get_rt_origins(tweet):
        # Regex adapted from
        # http://stackoverflow.com/questions/655903/python-regular-expression-for-retweets
        rt_patterns = re.compile(r"(RT|via)((?:\b\W*@\w+)+)", re.IGNORECASE)
        rt_origins = []
        # Inspect the tweet to see if it was produced with /statuses/retweet/:id
        # See http://dev.twitter.com/doc/post/statuses/retweet/:id
        if tweet.has_key('retweet_count'):
            if tweet['retweet_count'] > 0:
                rt_origins += [ tweet['user']['name'].lower() ]
        # Also, inspect the tweet for the presence of "legacy" retweet
        # patterns such as "RT" and "via".
        try:
            rt_origins += [
            mention.strip()
            for mention in rt_patterns.findall(tweet['text'])[0][1].split()
            ]
        except IndexError, e:
            pass
            # Filter out any duplicates
        return list(set([rto.strip("@").lower() for rto in rt_origins]))

    def create_rt_graph(tweets):
        g = nx.DiGraph()
        for tweet in tweets:
            rt_origins = get_rt_origins(tweet)
            if not rt_origins:
                continue
            for rt_origin in rt_origins:
                print rt_origin.encode('ascii', 'ignore') + ", "  + tweet['user']['name'].encode('ascii', 'ignore')
                if rt_origin == "leisecarj":
                    pass
                g.add_edge(rt_origin.encode('ascii', 'ignore'), tweet['user']['name'].encode('ascii', 'ignore'), {'tweet_id': tweet['id']})
                g.node[tweet['user']['name'].encode('ascii', 'ignore')] = {"img":tweet['user']['profile_image_url']}
                try:
                    if 'retweeted_status' in tweet:
                        g.node[rt_origin.encode('ascii', 'ignore')] = {"img":tweet['retweeted_status']['user']['profile_image_url']}
                    else:
                        g.node[rt_origin.encode('ascii', 'ignore')] = {"img":"https://twitter.com/favicon.ico"}
                except:
                    pass

        return g

    def write_d3js_output(g, out_file):
        nodes = g.nodes()
        indexed_nodes = {}
        idx = 0
        for n in nodes:
            indexed_nodes.update([(n, idx,)])
            idx += 1
            links = []
        groups = {}
        for n1, n2 in g.edges():
            if groups.has_key(indexed_nodes[n1]):
                groups[indexed_nodes[n1]].append(indexed_nodes[n2])
            else:
                groups[indexed_nodes[n1]] = [indexed_nodes[n1], indexed_nodes[n2]]
            links.append({'source' : indexed_nodes[n2],
                        'target' : indexed_nodes[n1]})

        # merging groups

        jsond = {"nodes":[], "links":links};


        finalgroups = {}
        while True:
            finalgroups = getMergeGroups(nodes, finalgroups, groups)
            print str(len(finalgroups)) + " - " + str(len(groups))
            if len(finalgroups) == len(groups):
                break
            groups = finalgroups
            finalgroups = {}


        idx = 0
        for n in nodes:
            for k in finalgroups.keys():
                if idx in finalgroups[k]:
                    try:
                        img = g.node[n]["img"]
                    except:
                        print n

                    no = {"img":img, "nodeName": n, "group": k}
                    jsond["nodes"].append(no)
                    break
            idx += 1
        json_data = json.dumps(jsond, indent=4)
        if not os.path.isdir('out'):
            os.mkdir('out')
        f = open(out_file, 'w')
        f.write(json_data)
        f.close()
        print >> sys.stderr, 'Data file written to: %s' % f.name

    def getMergeGroups(nodes, finalgroups, groups):
        idx = 0
        for n in nodes:
            glist = []
            for k in groups.keys():
                if idx in groups[k]:
                    glist.append(k)
            if len(glist) > 0:
                id = glist[0]
                if len(glist) > 1:
                    #merge groups

                    finalgroups[id] = []
                    for g in glist:
                        for t in groups[g]:
                            finalgroups[id].append(t);
                        del groups[g]
                else:
                    finalgroups[id] = groups[id]


            idx +=1
        return finalgroups;

    def __init__(self, work):
        try:
            # Your Mongo query
            connection = pymongo.Connection("177.70.97.184")
            db = connection.sptrans
            all_tweets = db['tweets'].find({"$text":{ "$search":work}})

            g = create_rt_graph(all_tweets)
            # Print out some stats.
            print >> sys.stderr, "Number nodes:", g.number_of_nodes()
            print >> sys.stderr, "Num edges:", g.number_of_edges()
            print >> sys.stderr, "Num connected components:", len(list(nx.connected_components(g.to_undirected())))
            print >> sys.stderr, "Node degrees:", sorted(nx.degree(g))
            # criando o json para o d3js
            write_d3js_output(g, work+'.json')
            return True
        except:
            return False

